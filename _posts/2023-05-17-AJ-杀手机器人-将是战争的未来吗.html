---
layout: post
title: "“杀手机器人”将是战争的未来吗？"
date: 2023-05-17 11:36:04.000000000 +08:00
link: http://chinese.aljazeera.net/news/military/2023/5/16/%e6%9d%80%e6%89%8b%e6%9c%ba%e5%99%a8%e4%ba%ba%e5%b0%86%e6%98%af%e6%88%98%e4%ba%89%e7%9a%84%e6%9c%aa%e6%9d%a5%e5%90%97
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>人类正站在一个战争新时代的边缘。</p>
<p>在人工智能快速发展的推动下，无需军官指挥攻击或者士兵扣动扳机，即可识别、瞄准并自行决定杀死人类的武器平台，正在迅速改变地球冲突的未来。</p>
<p>官方称之为致命自主武器系统(LAWS)，但批评者则称之为“杀手机器人”。近年来，包括美国、中国、英国、印度、伊朗、以色列、韩国、俄罗斯和土耳其在内的许多国家都大力投资开发此类武器。</p>
<p>联合国出台的一份<a href="https://lieber.westpoint.edu/kargu-2-autonomous-attack-drone-legal-ethical/">报告</a>指出，土耳其制造的全自动模式“卡古-2”无人机（Kargu-2）标志着这个新时代的到来——在利比亚持续不断的冲突中，该型无人机于2020年袭击了冲突中的战斗人员。</p>
<p>自主型无人机也在乌克兰战争中发挥了至关重要的作用——莫斯科和基辅都部署了这类无人驾驶的武器来打击敌方的士兵和基础设施。</p>
<p>此类机器的出现和传播引发了全球专家、活动人士以及外交官员之间的激烈辩论——他们正在努力辨别使用机器人可能带来的好处以及潜在的风险，并考虑是否应该阻止它们，以及应该如何阻止它们。</p>
<p>然而，在日益分化的地缘政治格局中，国际社会能否就这些机器达成共识？此类武器造成的道德、法律和技术威胁，是否迫使人类必须在它们占领战场之前将其制止？全面禁止是否可行？或者出台一套相关的法规是否才是更为现实的选择？半岛电视台记者向该领域内的专家提出了上述这些问题。</p>
<p><strong>简短的回答：</strong>完全禁止自主武器系统似乎不太可能很快实现。然而，越来越多的声音——尤其是来自全球南方的声音——呼吁对其进行监管。专家们认为，针对使用化学武器的那种全球禁令是可能的。主要军事强国可能对此类系统可能给他们带来的潜在战场优势很感兴趣，但是政府和军方之外似乎对它们兴趣不大。</p>
<figure id="attachment_433655" aria-describedby="caption-attachment-433655" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/AP22305549505318-1683777549-1684238233.jpg?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-433655">2022年10月17日，一架无人机出现在乌克兰基辅的天空中，并在几秒钟之后袭击了当地的建筑物 (美联社)</figcaption></figure>
<h3>“无法消除第三次世界大战的风险”</h3>
<p>今年3月下旬，总部位于伦敦的查塔姆研究所的助理研究员亚斯敏·阿菲娜向英国议会上议院描述了美国国家安全局(NSA)曾如何曾错误地将半岛电视台的一名记者认定为基地组织的信使。这种标记也导致了这名记者被列入美国观察名单，但这一切直到2013年，才随着美国国家安全局前承包商爱德华·斯诺登泄露的文件而曝光。</p>
<p>阿菲娜在她的证词中表示，该事件背后的监视系统本身并不是“武器系统，但它具有杀伤力”，“如果你要打击这些目标，即记者，那么这绝对是违反国际人道主义法的考虑。”</p>
<p>澳大利亚悉尼新南威尔士大学的人工智能专家托比·沃尔什担心这类致命自主武器系统可能会引发升级事件的连锁反应。</p>
<p>沃尔什在提交给英国上议院的书面证词中写道，“我们知道当我们将复杂的计算机系统置于不确定和竞争激烈的环境中时会发生些什么。这被称为股票市场。”</p>
<p>他补充称，“阻止危险的反馈循环和不良结果的唯一方法，就是使用断路器。在股市上，一旦遇到这种情况，我们可以简单地进行平仓交易。但我们却无力取消第三次世界大战的开始。”</p>
<p>沃尔什告诉半岛电视台记者，这并不意味着研究人员应当停止开发自动武器系统背后的技术。他还表示，这项技术可以在其他领域带来好处。</p>
<p>例如，用于避免与行人碰撞的汽车安全系统中使用的相同算法，将“成为用于识别战斗人员、跟踪他们的自主无人机的算法——这个指令将被变来杀死他们，而不再是避开他们”，他还认为，“拒绝让这个世界”有机会减少道路上的死亡人数，这在“道德上是错误的”。</p>
<p>沃尔什指出，相反，答案可能在于效仿“相对成功的化学武器监管”。</p>
<p>当使用化学武器时，它们会成为头版头条并引发全球抗议。联合国化学武器公约禁止这类武器的开发、生产、储存和使用。这一点，再加上围绕化学武器的国际禁忌，也成功地阻止了主要军火公司生产化学武器。</p>
<p>沃尔什表示，“我们无法把潘多拉魔盒收回去，但是这些措施似乎在很大程度上限制了当今世界各地战场上化学武器的滥用。”</p>
<figure id="attachment_433660" aria-describedby="caption-attachment-433660" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/2022-03-24T145529Z_1450494998_RC2X8T9Q6S05_RTRMADP_3_UKRAINE-CRISIS-POLAND-1683777362-1684238315.jpg?w=770&amp;resize=770%2C514" alt data-recalc-dims="1" /><figcaption id="caption-attachment-433660">2022年3月24日，俄罗斯对乌克兰的战争期间，在波兰一个机场内拍摄到的美国陆军MIM-104爱国者地对空导弹系统发射器，它们可以在没有人为干预的情况下识别、选择和攻击目标 (路透社)</figcaption></figure>
<h3>收益和风险</h3>
<p>可以肯定的是，从军事角度来看，人工智能驱动的自主武器系统存在它的优势。</p>
<p>它们可以在不使用士兵的情况下执行一些战场任务，从而降低人员伤亡的风险。其支持者们认为，嵌入这些系统的尖端技术，可以消除或减少决策中的人为错误并消除偏见。至少从理论上来看，提高目标定位的准确性可以减少意外的人员伤亡。</p>
<p>自主武器系统也可以部署用于防御能力，其闪电般快速的检测算法能够以比人类更高的效率和准确性来检测和消除潜在的威胁。</p>
<p>然而，对于许多专家和人权组织而言，这类武器存在的风险超出了它们所拥有的任何潜在优势——从在没有监督的情况下出现技术故障的可能性，到对国际法的违反，以及对这类作出生死决定的冷漠机器所存在的道德担忧。</p>
<p>所有这些担忧的核心，在于对问责机制的质疑。</p>
<p>在2019年，《联合国特定常规武器公约》(CCW)的126个缔约国同意了由联合国任命的专家组推荐的11项指导<a href="https://disarmament.unoda.org/the-convention-on-certain-conventional-weapons/background-on-laws-in-the-ccw/">原则</a>，以解决对自主武器的担忧。</p>
<p>在这些原则中存在一项决定，即国际人道主义法将充分适用于此类武器的潜在发展。但是专家们表示，尚不清楚该原则将如何被应用于战争的迷雾之中。例如，如果有一个机器人犯下了战争罪，那么，负责冲突战区的指挥官是否会被认为负有责任？还是说这种责任会被归咎于决定部署这类机器的高层？武器制造商又会为此负责吗？</p>
<p>斯德哥尔摩国际和平研究所的研究人员文森特·博拉宁、玛尔塔·博，在今年3月撰写的一篇<a href="https://blogs.icrc.org/law-and-policy/2023/03/02/three-lessons-autonomous-weapons-systems-ihl/">文章</a>中指出，所有这些都“代表了政策对话中的重大分歧”。</p>
<p>博拉宁告诉半岛电视台记者，目前甚至没有针对自主武器系统的“官方或国际公认的定义”，尽管大多数国家都认为，“关键因素是该系统将能够在没有人为干预的情况下识别、选择和攻击目标”。</p>
<p>根据斯德哥尔摩国际和平研究所人工智能项目治理主任博拉宁的说法，如今已经投入使用的武器系统符合这一描述。其中一个例子是由美国制造的MIM-104爱国者地对空导弹系统——该系统目前被包括沙特阿拉伯和以色列在内的许多国家使用。</p>
<p>博拉宁表示，“我们讨论的是一种能力，一种可以用于不同类型的武器系统的功能，它们可以拥有各种形状和形式，并且可以用于不同类型的任务。”</p>
<p>“因此，如果你要禁止某些东西”，他解释称，“你就必须准确缩小至你认为存在特别问题的武器或者场景的类型上。”</p>
<p>他还指出，与全面禁止相比，一套两级法规将是一个更为现实的结果，一些武器系统将被禁止，而另一些则在满足一套严格要求的情况下被允许使用。</p>
<p>博拉宁表示，“现在的主要问题在于，从基本上来看，哪些元素会被装入这两个桶内？”</p>
<p>这是各个国家尚未达成共识的一个问题。</p>
<figure id="attachment_433664" aria-describedby="caption-attachment-433664" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/2019-12-19T090026Z_793777653_RC29YD9NZEAC_RTRMADP_3_UN-FUNDING-1683778611-1684238378.jpg?w=770&amp;resize=770%2C578" alt data-recalc-dims="1" /><figcaption id="caption-attachment-433664">2019年11月15日，在瑞士日内瓦出席联合国致命自主武器会议的各国代表 (路透社)</figcaption></figure>
<h3>政治或法律监管？</h3>
<p>在如何对待自主武器的问题上，各国之间存在着更为根本的分歧：世界应该寻求一套具有法律约束力的规则，还是仅仅寻求一份政治意图声明？</p>
<p>一项政治宣言可能以任何形式构成，但却很可能包括一份公开声明，主要大国将在该声明中陈述他们在该问题上的共同立场，并且承诺遵守文件中规定的原则要点。这可能看起来像是中国、俄罗斯、英国、美国和法国在2022年1月签署的关于防止核战争和避免军备竞赛的<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2022/01/03/p5-statement-on-preventing-nuclear-war-and-avoiding-arms-races/">联合声明</a>，它们在其中申明，核战争“没有赢家，绝不能打”。</p>
<p>博拉宁认为，这是一个各国“有着截然不同的看法”的问题。俄罗斯对反对具有法律约束力的文书一直“非常开放”，而英国和美国也对此持批评态度，认为它“为时过早”，并寻求达成一项政治宣言作为迈出的第一步。</p>
<p>其他一些国家，例如中国和印度，则持更加模棱两可的立场。</p>
<p>中国支持禁止使用完全自主的武器，但并不禁止开发这类武器——这一立场符合这样一种观点，即世界上一些最危险的军事工具（包括核武器在内），可以被作为防御性的威慑力量。</p>
<p>中国国内的军火工业已经适时推进了此类技术的开发，包括可以成组飞行并独立攻击目标的“河豚”A2无人机。此外，机密的912项目还旨在在未来几年内开发水下机器人。</p>
<p>与此同时，印度也表达了对这类扩大各国技术鸿沟的机器竞争的关注，以及对包括非国家行为者在内的各方扩大对杀手机器人的使用的担忧，但同时它也在加倍关注自身的自主武器系统开发。</p>
<p>很难衡量各国军方究竟投入了多少资源来开发这类武器系统，但是国际特赦组织在2021年发布的一份报告指出，几个主要军事大国正在“大力投资自主系统的开发”。并且指出，英国正在开发一款无人驾驶的自主无人机，并且可以在编程区域内识别目标，“而俄罗斯则已经打造了一款可以安装机枪或者榴弹发射器的机器人坦克”。</p>
<p>自主功能还可以被添加至现有的或者正在开发的技术中，例如美国制造的Switchblade 600游荡式导弹。</p>
<p>对此类武器系统的真正抵制，来自南半球的大部分地区——尤其是拉丁美洲、非洲和中东地区。这些地区的国家正在寻求具有法律约束力的法规。</p>
<p>最近领导这场运动的，是一个已向世界表明没有军队也可以确保和平的国家。</p>
<figure id="attachment_433668" aria-describedby="caption-attachment-433668" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/2019-03-21T092518Z_187370127_RC16080EEC40_RTRMADP_3_GERMANY-ROBOTS-1683778752-1684238431.jpg?w=770&amp;resize=770%2C454" alt data-recalc-dims="1" /><figcaption id="caption-attachment-433668">2019年3月21日，反对致命自主武器或所谓的“杀手机器人”的非政府组织的积极分子在德国柏林勃兰登堡门举行抗议活动 (路透社)</figcaption></figure>
<h3>“和平的文化观”</h3>
<p>在2月份，哥斯达黎加政府与当地非政府组织“FUNPADEM”一起组织了一场区域会议，而几乎所有的拉丁美洲国家和加勒比国家都派代表参加了这场会议。</p>
<p>在这场会议上，超过30个国家通过的《<a href="https://conferenciaawscostarica2023.com/wp-content/uploads/2023/02/EN-Communique-of-La-Ribera-de-Belen-Costa-Rica-February-23-24-2023..pdf">贝伦公报</a>》（Belén Communiqué）强调了自主武器系统的危险，并且呼吁国际社会通过“发展和加强国际法律框架”来应对这些危险。</p>
<p>“FUNPADEM”的项目技术员布拉登·马塔·阿吉拉尔告诉半岛电视台记者，“这是我们基于我们和平的文化观而构建的国家立场。”</p>
<p>阿吉拉尔解释称，哥斯达黎加的军队于1948年被废除，但它仍然是该地区最稳定的国家之一。这一事实使“其他国家和哥斯达黎加在看待实施这些具有法律约束力的文件的方式上，存在巨大的差异”。</p>
<p>他还表示，哥斯达黎加正寻求完全禁止完全自主武器，并实施法规来控制半自主武器的使用和研发。</p>
<p>“阻止杀人机器人运动”——寻求先发制人地禁止致命自主武器系统的非政府组织联盟，以及红十字国际委员会(ICRC)等团体，也在哥斯达黎加举行的会议上表现出了很强的影响力。</p>
<p>随后在3月25日，多米尼加共和国举行伊比利亚-美洲峰会，22位西葡语系国家元首在这场会议上发布了一项<a href="https://www.segib.org/wp-content/uploads/11.-Comunicado-especial-sobre-el-impacto-social-y-humanitario-de-las-armas-autonomas_Es.pdf">联合声明</a>，并呼吁“谈判一项具有法律约束力的国际文书，并为武器系统的自主性设置禁令与规定”。</p>
<p>两天之后，这种情绪得到了回应——包括伯利兹、哥斯达黎加、萨尔瓦多、危地马拉、洪都拉斯、尼加拉瓜和巴拿马在内的中美洲一体化体系成员国也通过了类似的声明，并呼吁开展紧急谈判。</p>
<p>非洲和中东地区的多个国家——阿尔及利亚、纳米比亚、加纳、乌干达、津巴布韦、摩洛哥、埃及、约旦、伊拉克和巴勒斯坦，在过去的10年内一直呼吁全面禁止完全自主的武器系统。而南非等其他国家则呼吁制定相关法规，但并未寻求全面禁止这类系统。</p>
<p>沃尔什表示，所有这些势头都表明存在立法的意愿。“我们已经看到数十个甚至更多的国家在联合国会议上呼吁对此进行监管。我们已经看到欧洲议会投票支持它。我们已经看到非洲联盟对此投下了赞成票。”</p>
<p>但是，一些专家认为，任何谈判取得成功的关键要素——信任——已处于缺失状态。</p>
<figure id="attachment_433672" aria-describedby="caption-attachment-433672" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/05/AP21320044946962-1683780242-1684238530.jpg?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-433672">2021年11月15日，美国总统乔·拜登在华盛顿特区白宫罗斯福厅与中国国家主席习近平举行在线会晤，美国国务卿安东尼·布林肯（右）也出现在会谈现场。专家们认为，作为两个引领自主武器发展的国家，中美之间的紧张关系可能会影响就规范这类武器使用而建立全球共识的努力 (美联社)</figcaption></figure>
<h3>信任与尊重</h3>
<p>分析人士表示，在地缘政治紧张局势加剧的情况下，许多国家担心他们是否能够相信竞争对手出台的官方声明。</p>
<p>缺乏信任将在两个层面上发挥作用。由于像《特定常规武器公约》（CCW）这样的国际公约取决于共识，沃尔什指出，“只需要一个国家的破坏，就能够阻止谈判取得进展。”</p>
<p>但是，即使出台了新的国际法或者一套新的法规，它们是否会得到有效的实施呢？沃尔什认为，这是一个悬而未决的问题，因为许多国家“不再按照基于规则的秩序行事。”</p>
<p>博拉宁也认同这些担忧。</p>
<p>博拉宁表示，“各国可以同意——这是一回事，但合规又是另一回事。”</p>
<p>他补充称，“我认为一些国家担心，如果它们就雄心勃勃的监管框架达成一致，它们可能会搬起石头砸自己的脚。”对此，他解释称，如果它们的对手不遵守规则并且开发了这类武器，那么这将使它们处于战略劣势。</p>
<p>然而，他又指出，这种风险并不意味着“我们不应该继续努力就负责任行为的新规范达成共识”。</p>
<p>他说，一项传统的担忧——任何国际法都无法跟上技术飞速发展的步伐——已经得到了解决，而联合国的方法现在侧重于与技术无关的法规。</p>
<p>尽管如此，这场辩论还存在更多的基本问题，包括在没有任何人参与决策过程的情况下夺走人们生命的机器的道德问题。</p>
<p>自首次出现在1899年海牙公约(II)的序言​​中以来，《马顿斯条款》已经成为了武装冲突法的一部分，并被经常用于讨论自主武器系统的伦理问题。该条款宣称，在没有关于某个主题的具体条约法规的情况下，人们仍然受到“习俗”、“人道主义原则”和“公众良知要求”的保护。</p>
<p>在2019年，联合国秘书长安东尼奥·古特雷斯表示，具有在没有人类参与的情况下夺取他人生命的能力的机器，是“政治上不可接受的”，也是“道德上令人厌恶的”。</p>
<p>沃尔什为这项研究而采访过许多军事人员，而他们似乎也对完全自主的武器感到不安。</p>
<p>沃尔什指出，他发现“最为普遍的情况是，排名情况越靠下，离战场越近，就会越多地反对与机器人作战的想法”。</p>
<p>沃尔什表示，除了法律、法规和地缘政治之外，还存在一个更为根本的问题，那就是机器缺乏人类同理心来作出如此关键的决定。</p>
<p>“这是对人类尊严的不尊重。”</p>
</div><div>来源<!-- --> : <!-- -->半岛电视台</div>
